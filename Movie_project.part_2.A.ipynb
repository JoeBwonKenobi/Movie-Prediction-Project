{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24be188",
   "metadata": {},
   "source": [
    "## **Movie Prediction ptoject**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627553c",
   "metadata": {},
   "source": [
    "Joe Lardie\n",
    "\n",
    "2/19/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da6954a",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4f4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Data Analysis Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File Handling\n",
    "import gzip\n",
    "\n",
    "# System Utilities\n",
    "import os  \n",
    "import json \n",
    "import math\n",
    "import time\n",
    "\n",
    "# Third-Party APIs and Progress Bar\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0da0bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['api-key'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/Users/davyd/.secret/tmbd_api.json', 'r')as f:\n",
    "    login = json.load(f)\n",
    "##Display the keys of the loaded dictionary \n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67ec5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API\n",
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3170064",
   "metadata": {},
   "source": [
    "## **Importing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f01cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Basics data set\n",
    "basics = pd.read_csv(\"https://datasets.imdbws.com/title.basics.tsv.gz\",sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c52cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading akas data set\n",
    "akas = pd.read_csv(\"https://datasets.imdbws.com/title.akas.tsv.gz\",sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45203c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading ratings data set\n",
    "ratings = pd.read_csv(\"https://datasets.imdbws.com/title.ratings.tsv.gz\",sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3ae35",
   "metadata": {},
   "source": [
    "## **Part 2 A**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad741a07",
   "metadata": {},
   "source": [
    "# **Custom Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200564b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akas.csv.gz',\n",
       " 'basics.csv.gz',\n",
       " 'final_tmdb_data_2000 (1).csv.gz',\n",
       " 'final_tmdb_data_2000 (2).csv.gz',\n",
       " 'final_tmdb_data_2000 (3).csv.gz',\n",
       " 'final_tmdb_data_2000.csv.gz',\n",
       " 'final_tmdb_data_2001.csv.gz',\n",
       " 'final_tmdb_data_2002.csv.gz',\n",
       " 'final_tmdb_data_2003.csv.gz',\n",
       " 'final_tmdb_data_2004.csv.gz',\n",
       " 'final_tmdb_data_2005.csv.gz',\n",
       " 'final_tmdb_data_2006.csv.gz',\n",
       " 'final_tmdb_data_2007.csv.gz',\n",
       " 'final_tmdb_data_2008.csv.gz',\n",
       " 'final_tmdb_data_2009.csv.gz',\n",
       " 'final_tmdb_data_2010.csv.gz',\n",
       " 'final_tmdb_data_2011.csv.gz',\n",
       " 'final_tmdb_data_2012.csv.gz',\n",
       " 'final_tmdb_data_2013.csv.gz',\n",
       " 'final_tmdb_data_2014.csv.gz',\n",
       " 'final_tmdb_data_2015.csv.gz',\n",
       " 'final_tmdb_data_2016.csv.gz',\n",
       " 'final_tmdb_data_2017.csv.gz',\n",
       " 'final_tmdb_data_2018.csv.gz',\n",
       " 'final_tmdb_data_2019.csv.gz',\n",
       " 'final_tmdb_data_2020.csv.gz',\n",
       " 'ratings.csv.gz',\n",
       " 'tmdb_api_results_2000.csv.gz',\n",
       " 'tmdb_api_results_2000.json',\n",
       " 'tmdb_api_results_2001.json',\n",
       " 'tmdb_api_results_2002.json',\n",
       " 'tmdb_api_results_2003.json',\n",
       " 'tmdb_api_results_2004.json',\n",
       " 'tmdb_api_results_2005.json',\n",
       " 'tmdb_api_results_2006.json',\n",
       " 'tmdb_api_results_2007.json',\n",
       " 'tmdb_api_results_2008.json',\n",
       " 'tmdb_api_results_2009.json',\n",
       " 'tmdb_api_results_2010.json',\n",
       " 'tmdb_api_results_2011.json',\n",
       " 'tmdb_api_results_2012.json',\n",
       " 'tmdb_api_results_2013.json',\n",
       " 'tmdb_api_results_2014.json',\n",
       " 'tmdb_api_results_2015.json',\n",
       " 'tmdb_api_results_2016.json',\n",
       " 'tmdb_api_results_2017.json',\n",
       " 'tmdb_api_results_2018.json',\n",
       " 'tmdb_api_results_2019.json',\n",
       " 'tmdb_api_results_2020.json',\n",
       " 'tmdb_api_results_2021.json',\n",
       " 'tmdb_api_results_2022.json',\n",
       " 'tmdb_results_combined.csv.gz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for DATA folder\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12cf40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Movie With Rating\n",
    "def get_movie_with_rating(movie_id):\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    info = movie.info()\n",
    "    \n",
    "    releases = movie.releases()\n",
    "    \n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1']=='US':\n",
    "            info['certification']=c['certification']\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b20e618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/9BBTo63ANSmhC4e6r62OJFuK2GL.jpg',\n",
       " 'belongs_to_collection': {'id': 86311,\n",
       "  'name': 'The Avengers Collection',\n",
       "  'poster_path': '/yFSIUVTCvgYrpalUktulvk3Gi5Y.jpg',\n",
       "  'backdrop_path': '/zuW6fOiusv4X9nnW3paHGfXcSll.jpg'},\n",
       " 'budget': 220000000,\n",
       " 'genres': [{'id': 878, 'name': 'Science Fiction'},\n",
       "  {'id': 28, 'name': 'Action'},\n",
       "  {'id': 12, 'name': 'Adventure'}],\n",
       " 'homepage': 'https://www.marvel.com/movies/the-avengers',\n",
       " 'id': 24428,\n",
       " 'imdb_id': 'tt0848228',\n",
       " 'origin_country': ['US'],\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Avengers',\n",
       " 'overview': 'When an unexpected enemy emerges and threatens global safety and security, Nick Fury, director of the international peacekeeping agency known as S.H.I.E.L.D., finds himself in need of a team to pull the world back from the brink of disaster. Spanning the globe, a daring recruitment effort begins!',\n",
       " 'popularity': 144.559,\n",
       " 'poster_path': '/RYMX2wcKCBAr24UyPD7xwmjaTn.jpg',\n",
       " 'production_companies': [{'id': 420,\n",
       "   'logo_path': '/hUzeosd33nzE5MCNsZxCGEKTXaQ.png',\n",
       "   'name': 'Marvel Studios',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '2012-04-25',\n",
       " 'revenue': 1518815515,\n",
       " 'runtime': 143,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'},\n",
       "  {'english_name': 'Hindi', 'iso_639_1': 'hi', 'name': 'हिन्दी'},\n",
       "  {'english_name': 'Russian', 'iso_639_1': 'ru', 'name': 'Pусский'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Some assembly required.',\n",
       " 'title': 'The Avengers',\n",
       " 'video': False,\n",
       " 'vote_average': 7.718,\n",
       " 'vote_count': 30470,\n",
       " 'certification': 'PG-13'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test get_movie... function with Avengers \"tt0848228\"\n",
    "test = get_movie_with_rating(\"tt0848228\") \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a145f9c",
   "metadata": {},
   "source": [
    "# **Json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26351cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592cc9a",
   "metadata": {},
   "source": [
    "# **Create Required List for Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6bd047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an error list\n",
    "errors = [ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4f66f",
   "metadata": {},
   "source": [
    "# **Write Json data to CSV File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7becf5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae22524144f4586a627e61829d5282d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/tmdb_api_results_2000.json status True\n",
      "Data/tmdb_api_results_2001.json status True\n"
     ]
    }
   ],
   "source": [
    "# Defining Year parameter\n",
    "YEARS_TO_GET = [2000,2001]\n",
    "# Start of OUTER loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    #Defining the JSON file to store results for year\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "    ## Check if JSON_FILE exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    print(f'{JSON_FILE} status {file_exists}')\n",
    "    # If it does not exist: create it\n",
    "    if file_exists == False:\n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "    \n",
    "        #Saving new year as the current df\n",
    "        df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "        # saving movie ids to list\n",
    "        movie_ids = df['tconst'].copy()\n",
    "    \n",
    "        # Load existing data from json into a dataframe called \"previous_df\"\n",
    "        previous_df = pd.read_json(JSON_FILE)\n",
    "    \n",
    "        # filter out any ids that are already in the JSON_FILE\n",
    "        movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "    \n",
    "        #Get index and movie id from list\n",
    "        # INNER Loop\n",
    "        for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "            try:\n",
    "                # Retrieve then data for the movie id\n",
    "                temp = get_movie_with_rating(movie_id)  \n",
    "                # Append/extend results to existing file using a pre-made function\n",
    "                write_json(temp,JSON_FILE)\n",
    "                # Short 20 ms sleep to prevent overwhelming server\n",
    "                time.sleep(0.02)\n",
    "            \n",
    "            except Exception as e:\n",
    "                errors.append([movie_id, e])\n",
    "    \n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\",\n",
    "                         compression=\"gzip\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
